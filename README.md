# ğŸŒ Climate Policy Q&A Bot

A **Retrieval-Augmented Generation (RAG)** chatbot that answers complex **climate policy and sustainability questions** using authoritative global documents such as:

- The **Paris Agreement (UNFCCC)**
- **IPCC Synthesis Reports**
- **UNFCCC CMA reports**
- **EU Fit-for-55 Policy Briefings**
- **UNEP Emissions Gap Report 2024**

This project runs **entirely locally** using **Llama 3 (8B)** through **Ollama**, requiring no API keys or cloud dependencies.

---
*(This is where you should put your `demo.gif` file)*
![Climate Bot Demo](screenshots/demo.gif)
---

## ğŸ“– Table of Contents
- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Tech Stack](#-tech-stack)
- [Setup & Installation](#-setup--installation)
- [Usage](#-usage)
- [Project Files](#-project-files)
- [Future Enhancements](#-future-enhancements)
- [Author](#-author)

---

## ğŸ§© Overview

The **Climate Policy Q&A Bot** enables users to ask natural-language questions about climate policy, international agreements, or sustainability goals, and receive **context-grounded answers** based on official reports.

Itâ€™s built using **Retrieval-Augmented Generation (RAG)** â€” a combination of **semantic search** and **local LLM inference**.

ğŸ’¡ **Use Case Examples:**
- Policy analysts checking updates on national NDCs
- Students researching the Paris Agreement
- NGOs summarizing IPCC findings
- Journalists verifying facts on global climate targets

---

## âš™ï¸ Features

âœ… Answers grounded in real, official climate policy documents
âœ… Local model inference via **Ollama + Llama 3 (8B)**
âœ… Lightweight Retrieval-Augmented Generation pipeline
âœ… Cites sources (with PDF page references) for verifiability
âœ… Multiple AI personas: `plain`, `policy`, `journalist`
âœ… Interactive chat UI built with **Streamlit**
âœ… No external API costs or internet dependence

---

## ğŸ§  Architecture

The diagram below illustrates the RAG data flow, from document ingestion to answer generation.

```plaintext
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  PDF Climate Reports     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
           (ingest.py: Text Extraction & Chunking)
                   â”‚
                   â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  TF-IDF Vector Index     â”‚
      â”‚  (Scikit-learn)          â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
           (app.py: Cosine Similarity Search)
                   â”‚
                   â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Context + Query â†’ LLM   â”‚
      â”‚  (Llama 3 via Ollama)    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» Tech Stack

| Component         | Technology / Library                                       |
| ----------------- | ---------------------------------------------------------- |
| **Language** | Python 3.9+                                                |
| **LLM Backend** | Llama 3 (8B) via **Ollama** |
| **Retrieval** | TF-IDF with **Scikit-Learn** |
| **Interface** | **Streamlit** |
| **Doc Parsing** | **PyMuPDF** |
| **Environment** | venv / virtualenv                                          |

---

## ğŸ§° Setup & Installation

#### 1ï¸âƒ£ Clone the Repository
```bash
git clone [https://github.com/YOUR_USERNAME/climate-policy-rag-bot.git](https://github.com/YOUR_USERNAME/climate-policy-rag-bot.git)
cd climate-policy-rag-bot
```

#### 2ï¸âƒ£ Create and Activate a Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate
```

#### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

#### 4ï¸âƒ£ Install and Run Ollama
Follow the instructions on [ollama.ai](https://ollama.ai/) to install Ollama. Then, pull the Llama 3 model and start the server.

```bash
# Pull the model
ollama pull llama3:8b

# Run the server (keep this terminal open)
ollama serve
```

#### 5ï¸âƒ£ Configure Environment Variables
Create a `.env` file in the project root and add the following:
```env
OPENAI_API_KEY="ollama"
OPENAI_BASE_URL="http://localhost:11434/v1"
LLM_MODEL="llama3:8b"
```

---

## ğŸš€ Usage

#### ğŸ–¥ï¸ Streamlit Mode (Recommended)
Run the Streamlit application for an interactive chat interface.

```bash
streamlit run app.py
```

#### ğŸ§­ CLI Mode
Alternatively, you can ask a single question directly from the terminal:

```bash
python app.py --question "What temperature goal is stated in the Paris Agreement?" --persona plain
```

---

## ğŸ“‚ Project Files

| File               | Description                                                                                                   |
| ------------------ | ------------------------------------------------------------------------------------------------------------- |
| `app.py`           | The main Streamlit web application that provides the chat interface and runs the RAG pipeline.       |
| `ingest.py`        | Parses PDFs, splits them into chunks, and builds the TF-IDF vector index (`index.pkl`).              |
| `eval.py`          | A script to evaluate the chatbot's performance on a custom set of question-answer pairs.            |
| `requirements.txt` | Lists the Python dependencies for the project.                                                 |
| `docs/`            | A directory to store the source PDF and text documents for the chatbot's knowledge base.                        |

---

## ğŸ”® Future Enhancements

- **Vector Database**: Replace the pickled index with **ChromaDB** or **FAISS** for more scalable vector storage and retrieval.
- **Reranking**: Integrate a **Cross-Encoder** model to re-rank the search results for improved relevance before sending them to the LLM.
- **Deployment**: Package the application in a **Docker** container and deploy it on **Hugging Face Spaces** or Streamlit Cloud.
- **Evaluation Dashboard**: Build a Streamlit dashboard to visualize the results from `eval.py` and track performance changes.

---

## ğŸ‘©â€ğŸ’» Author

**Nivesara Tirupati**
- ğŸ“ Data Scientist | NLP & ML | Climate Tech | Policy Innovation
- ğŸ”— [LinkedIn](YOUR_LINKEDIN_URL)
- ğŸ™ [GitHub](https://github.com/YOUR_GITHUB_USERNAME)
